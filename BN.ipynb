{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc035a02-9e8e-4ce0-bd83-40b434c16c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, Predictive, config_enumerate\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal, AutoDelta\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45014482-f9f3-4e43-a82d-88ce066eca8b",
   "metadata": {},
   "source": [
    "### Example 1: Mixed continuous-discrete Bayesian network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12ac954-b63a-4d85-bbc8-ca06f4d2168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @config_enumerate is \"required\" (not strictly) because we have a discrete variable, A\n",
    "# See https://pyro.ai/examples/enumeration.html\n",
    "@config_enumerate\n",
    "def BN_model(A_obs=None, B_obs=None, C_obs=None, N=None):\n",
    "    if A_obs is not None:\n",
    "        if B_obs is not None:\n",
    "            assert len(A_obs) == len(B_obs)\n",
    "        if C_obs is not None:\n",
    "            assert len(A_obs) == len(C_obs)\n",
    "        if N is not None:\n",
    "            assert N == len(A_obs)\n",
    "        else:\n",
    "            N = len(A_obs)\n",
    "\n",
    "        A_obs = A_obs.squeeze()\n",
    "\n",
    "    if B_obs is not None:\n",
    "        if N is not None:\n",
    "            assert N == len(B_obs)\n",
    "        else:\n",
    "            N = len(B_obs)\n",
    "\n",
    "        B_obs = B_obs.squeeze()\n",
    "\n",
    "    if C_obs is not None:\n",
    "        if N is not None:\n",
    "            assert N == len(C_obs)\n",
    "        else:\n",
    "            N = len(C_obs)\n",
    "\n",
    "        C_obs = C_obs.squeeze()\n",
    "\n",
    "    if N is None:\n",
    "        N = 1\n",
    "\n",
    "    # prior distribution over weights of the categorical distribution from which A is drawn\n",
    "    # pyro distinguishes between the \"batch_shape\" (=shape of samples drawn) and the \"event_shape\" (=shape of a single\n",
    "    # RV drawn from this distribution) of a tensor. We need to tell it that this 3-D thing describes a single RV (and\n",
    "    # similarly for the other priors below). See https://pyro.ai/examples/tensor_shapes.html for details.\n",
    "    weights = pyro.sample('weights', dist.Dirichlet(torch.ones(3)).to_event())\n",
    "\n",
    "    # prior distribution over parameters (> 0) of the beta distribution from which B is drawn\n",
    "    beta_concentrations = pyro.sample('beta_concentrations', dist.Gamma(concentration=torch.tensor([2., 2.]),\n",
    "                                                                        rate=torch.tensor([0.5, 0.5])).to_event())\n",
    "\n",
    "    # prior distribution over weigths k in p_C = B*k(A)\n",
    "    C_weights = pyro.sample('C_weights', dist.Beta(torch.tensor([1., 1., 1.]), torch.tensor([1., 1., 1.])).to_event())\n",
    "\n",
    "    if N > 0:\n",
    "        with pyro.plate('data', N):\n",
    "            A = pyro.sample('A', dist.Categorical(weights), obs=A_obs, infer={\"enumerate\": \"parallel\"})\n",
    "            B = pyro.sample('B', dist.Beta(beta_concentrations[0], beta_concentrations[1]), obs=B_obs)\n",
    "            C = pyro.sample('C', dist.Binomial(probs=B * C_weights[A]), obs=C_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c826e6-f28a-4cdf-9b8f-64e783ac1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model (needs graphviz - don't have it, cannot test)\n",
    "#pyro.render_model(lambda: BN_model(N=100), render_distributions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b1d648-7816-46f0-a046-0a91f821325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def summarize_samples(samples):\n",
    "    # Adapted from https://pyro.ai/examples/bayesian_regression.html#Model-Evaluation.\n",
    "    param_stats = {}\n",
    "    for k, v in samples.items():\n",
    "        if torch.is_floating_point(v):\n",
    "            param_stats[k] = {\n",
    "                \"mean\": torch.mean(v, 0),\n",
    "                \"std\": torch.std(v, 0),\n",
    "                \"5%\": v.kthvalue(int(len(v) * 0.05), dim=0)[0],\n",
    "                \"95%\": v.kthvalue(int(len(v) * 0.95), dim=0)[0],\n",
    "            }\n",
    "        else:\n",
    "            print(f'Dropping variable {k} from summary statistics since it is not a float.')\n",
    "    return param_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44063684-4518-41b6-967b-b7d49ac03e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: SAMPLES FROM PRIOR DISTRIBUTION\n",
      "\n",
      "Dropping variable A from summary statistics since it is not a float.\n",
      "{'B': {'5%': tensor([0.0493]),\n",
      "       '95%': tensor([0.9502]),\n",
      "       'mean': tensor([0.5027]),\n",
      "       'std': tensor([0.2781])},\n",
      " 'C': {'5%': tensor([0.]),\n",
      "       '95%': tensor([1.]),\n",
      "       'mean': tensor([0.2610]),\n",
      "       'std': tensor([0.4394])},\n",
      " 'C_weights': {'5%': tensor([[0.0520, 0.0519, 0.0496]]),\n",
      "               '95%': tensor([[0.9472, 0.9503, 0.9433]]),\n",
      "               'mean': tensor([[0.4884, 0.5059, 0.5031]]),\n",
      "               'std': tensor([[0.2873, 0.2875, 0.2881]])},\n",
      " 'beta_concentrations': {'5%': tensor([[0.7030, 0.7028]]),\n",
      "                         '95%': tensor([[9.3248, 8.5537]]),\n",
      "                         'mean': tensor([[3.9635, 3.7916]]),\n",
      "                         'std': tensor([[2.7857, 2.5253]])},\n",
      " 'weights': {'5%': tensor([[0.0299, 0.0250, 0.0338]]),\n",
      "             '95%': tensor([[0.7756, 0.7545, 0.7737]]),\n",
      "             'mean': tensor([[0.3442, 0.3132, 0.3426]]),\n",
      "             'std': tensor([[0.2337, 0.2315, 0.2373]])}}\n"
     ]
    }
   ],
   "source": [
    "# Sample from the prior distribution, see here: https://forum.pyro.ai/t/samples-from-prior-distribution/1740/2\n",
    "prior_samples = Predictive(BN_model, posterior_samples={}, num_samples=1000)()\n",
    "print(\"SUMMARY: SAMPLES FROM PRIOR DISTRIBUTION\\n\")\n",
    "pprint(summarize_samples(prior_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbdf2951-3826-4f22-abe6-c6aecec29620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: SAMPLES FROM CONDITIONED DISTRIBUTION\n",
      "\n",
      "Dropping variable A from summary statistics since it is not a float.\n",
      "{'B': {'5%': tensor([0.0011]),\n",
      "       '95%': tensor([0.6523]),\n",
      "       'mean': tensor([0.2009]),\n",
      "       'std': tensor([0.2133])},\n",
      " 'C': {'5%': tensor([0.]),\n",
      "       '95%': tensor([1.]),\n",
      "       'mean': tensor([0.0840]),\n",
      "       'std': tensor([0.2774])},\n",
      " 'C_weights': {'5%': tensor([[0.5000, 1.0000, 0.2000]]),\n",
      "               '95%': tensor([[0.5000, 1.0000, 0.2000]]),\n",
      "               'mean': tensor([[0.5000, 1.0000, 0.2000]]),\n",
      "               'std': tensor([[0., 0., 0.]])},\n",
      " 'beta_concentrations': {'5%': tensor([[0.5000, 2.0000]]),\n",
      "                         '95%': tensor([[0.5000, 2.0000]]),\n",
      "                         'mean': tensor([[0.5000, 2.0000]]),\n",
      "                         'std': tensor([[0., 0.]])},\n",
      " 'weights': {'5%': tensor([[0.2000, 0.2000, 0.6000]]),\n",
      "             '95%': tensor([[0.2000, 0.2000, 0.6000]]),\n",
      "             'mean': tensor([[0.2000, 0.2000, 0.6000]]),\n",
      "             'std': tensor([[0., 0., 0.]])}}\n"
     ]
    }
   ],
   "source": [
    "# Specify some parameters and sample from the parametrized model\n",
    "# we'll see below whether we can then estimate those params\n",
    "weights = torch.tensor([0.2, 0.2, 0.6])\n",
    "beta_concentrations = torch.tensor([0.5, 2.0])\n",
    "C_weights = torch.tensor([0.5, 1.0, 0.2])\n",
    "BN_model_conditioned = pyro.poutine.condition(BN_model, data={'weights': weights,\n",
    "                                                              'beta_concentrations': beta_concentrations,\n",
    "                                                              'C_weights': C_weights})\n",
    "parametrized_samples = Predictive(BN_model_conditioned, posterior_samples={}, num_samples=5000)()\n",
    "print(\"SUMMARY: SAMPLES FROM CONDITIONED DISTRIBUTION\\n\")\n",
    "pprint(summarize_samples(parametrized_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0871d602-1b48-4b3c-a0af-567e72f134c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try to estimate those parameters using SVI\n",
    "pyro.clear_param_store()\n",
    "# If you want to do MAP estimation instead (no uncertainty required), use AutoDelta instead. See https://pyro.ai/examples/mle_map.html.\n",
    "guide = AutoNormal(pyro.poutine.block(BN_model, hide=[\"A\", \"B\", \"C\"])) \n",
    "\n",
    "svi = SVI(model=BN_model,\n",
    "          guide=guide,\n",
    "          optim=ClippedAdam({\"lr\": 0.005, 'clip_norm': 1.0}),  # See here for how to use a more elaborate optimization scheme, e.g., with lr scheduling: https://pyro.ai/examples/svi_part_iv.html\n",
    "          loss=TraceEnum_ELBO(max_plate_nesting=1))  # if we didn't have a discrete variable, we'd use Trace_ELBO\n",
    "\n",
    "for i in range(5000):\n",
    "    loss = svi.step(parametrized_samples['A'], parametrized_samples['B'], parametrized_samples['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85157ee9-2061-47ed-9c4f-4ff2536d1e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: SAMPLES FROM POSTERIOR DISTRIBUTION\n",
      "\n",
      "{'C_weights': {'5%': tensor([[0.4581, 0.7719, 0.1719]]),\n",
      "               '95%': tensor([[0.6564, 0.9916, 0.2455]]),\n",
      "               'mean': tensor([[0.5603, 0.9311, 0.2078]]),\n",
      "               'std': tensor([[0.0598, 0.0733, 0.0224]])},\n",
      " 'beta_concentrations': {'5%': tensor([[0.4933, 1.9288]]),\n",
      "                         '95%': tensor([[0.5293, 2.0992]]),\n",
      "                         'mean': tensor([[0.5111, 2.0118]]),\n",
      "                         'std': tensor([[0.0111, 0.0519]])},\n",
      " 'weights': {'5%': tensor([[0.1835, 0.1877, 0.5827]]),\n",
      "             '95%': tensor([[0.2088, 0.2178, 0.6180]]),\n",
      "             'mean': tensor([[0.1962, 0.2029, 0.6009]]),\n",
      "             'std': tensor([[0.0078, 0.0090, 0.0109]])}}\n"
     ]
    }
   ],
   "source": [
    "# Did we estimate the parameters correctly?\n",
    "posterior_predictive = Predictive(BN_model, guide=guide, num_samples=1000, return_sites=(\"weights\", \"beta_concentrations\", \"C_weights\"))\n",
    "posterior_samples = posterior_predictive()\n",
    "print(\"SUMMARY: SAMPLES FROM POSTERIOR DISTRIBUTION\\n\")\n",
    "pprint(summarize_samples(posterior_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff3a16-90ae-445f-b2ff-0e759d997dd7",
   "metadata": {},
   "source": [
    "### Example 2: Purely discrete Bayesian network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe5e554-a264-42d3-bebe-23d3ad025d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @config_enumerate is \"required\" (not strictly) because we have a discrete variable, A\n",
    "# See https://pyro.ai/examples/enumeration.html\n",
    "@config_enumerate\n",
    "def BN_model(A_obs=None, B_obs=None, N=None):\n",
    "    if A_obs is not None:\n",
    "        if B_obs is not None:\n",
    "            assert len(A_obs) == len(B_obs)\n",
    "        if N is not None:\n",
    "            assert N == len(A_obs)\n",
    "        else:\n",
    "            N = len(A_obs)\n",
    "\n",
    "        A_obs = A_obs.squeeze()\n",
    "\n",
    "    if B_obs is not None:\n",
    "        if N is not None:\n",
    "            assert N == len(B_obs)\n",
    "        else:\n",
    "            N = len(B_obs)\n",
    "\n",
    "        B_obs = B_obs.squeeze()\n",
    "\n",
    "    if N is None:\n",
    "        N = 1\n",
    "        \n",
    "    # prior distribution over weights of the categorical distribution from which A is drawn\n",
    "    # pyro distinguishes between the \"batch_shape\" (=shape of samples drawn) and the \"event_shape\" (=shape of a single\n",
    "    # RV drawn from this distribution) of a tensor. We need to tell it that this 3-D thing describes a single RV (and\n",
    "    # similarly for the other priors below). See https://pyro.ai/examples/tensor_shapes.html for details.\n",
    "    A_weights = pyro.sample('A_weights', dist.Dirichlet(torch.ones(3)).to_event())\n",
    "\n",
    "    # prior distribution over weigths k in p_C = B*k(A)\n",
    "    #B_weight_params = \n",
    "    B_weights = pyro.sample('B_weights', dist.Beta(torch.tensor([1., 1., 1.]), torch.tensor([1., 1., 1.])).to_event())\n",
    "\n",
    "    with pyro.plate('data', N):\n",
    "        A = pyro.sample('A', dist.Categorical(A_weights), obs=A_obs, infer={\"enumerate\": \"parallel\"})\n",
    "        B = pyro.sample('B', dist.Binomial(probs=B_weights[A]), obs=B_obs, infer={\"enumerate\": \"parallel\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a30cf958-501c-4fe0-8036-0da4ef3c9b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: SAMPLES FROM CONDITIONED DISTRIBUTION\n",
      "\n",
      "Dropping variable A from summary statistics since it is not a float.\n",
      "{'A_weights': {'5%': tensor([[0.2000, 0.2000, 0.6000]]),\n",
      "               '95%': tensor([[0.2000, 0.2000, 0.6000]]),\n",
      "               'mean': tensor([[0.2000, 0.2000, 0.6000]]),\n",
      "               'std': tensor([[0., 0., 0.]])},\n",
      " 'B': {'5%': tensor([0.]),\n",
      "       '95%': tensor([1.]),\n",
      "       'mean': tensor([0.4194]),\n",
      "       'std': tensor([0.4935])},\n",
      " 'B_weights': {'5%': tensor([[0.5000, 1.0000, 0.2000]]),\n",
      "               '95%': tensor([[0.5000, 1.0000, 0.2000]]),\n",
      "               'mean': tensor([[0.5000, 1.0000, 0.2000]]),\n",
      "               'std': tensor([[0., 0., 0.]])}}\n"
     ]
    }
   ],
   "source": [
    "# Specify some parameters and sample from the parametrized model\n",
    "# we'll see below whether we can then estimate those params\n",
    "A_weights = torch.tensor([0.2, 0.2, 0.6])\n",
    "B_weights = torch.tensor([0.5, 1.0, 0.2])\n",
    "BN_model_conditioned = pyro.poutine.condition(BN_model, data={'A_weights': A_weights,\n",
    "                                                              'B_weights': B_weights})\n",
    "parametrized_samples = Predictive(BN_model_conditioned, posterior_samples={}, num_samples=5000)()\n",
    "print(\"SUMMARY: SAMPLES FROM CONDITIONED DISTRIBUTION\\n\")\n",
    "pprint(summarize_samples(parametrized_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2914aed5-2ba6-4ec9-92bf-992c4077ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try to estimate those parameters using SVI\n",
    "pyro.clear_param_store()\n",
    "# If you want to do MAP estimation instead (no uncertainty required), use AutoDelta instead. See https://pyro.ai/examples/mle_map.html.\n",
    "guide = AutoNormal(pyro.poutine.block(BN_model, hide=[\"A\", \"B\"])) \n",
    "\n",
    "svi = SVI(model=BN_model,\n",
    "          guide=guide,\n",
    "          optim=ClippedAdam({\"lr\": 0.005, 'clip_norm': 1.0}),  # See here for how to use a more elaborate optimization scheme, e.g., with lr scheduling: https://pyro.ai/examples/svi_part_iv.html\n",
    "          loss=TraceEnum_ELBO(max_plate_nesting=1))  # if we didn't have a discrete variable, we'd use Trace_ELBO\n",
    "\n",
    "for i in range(5000):\n",
    "    loss = svi.step(parametrized_samples['A'], parametrized_samples['B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23d6968f-e0ce-4ee2-a9a7-5a55dacf04ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: SAMPLES FROM POSTERIOR DISTRIBUTION\n",
      "\n",
      "{'A_weights': {'5%': tensor([[0.1867, 0.1828, 0.5880]]),\n",
      "               '95%': tensor([[0.2142, 0.2075, 0.6210]]),\n",
      "               'mean': tensor([[0.1998, 0.1952, 0.6050]]),\n",
      "               'std': tensor([[0.0084, 0.0074, 0.0100]])},\n",
      " 'B_weights': {'5%': tensor([[0.4745, 0.9939, 0.1898]]),\n",
      "               '95%': tensor([[0.5497, 0.9999, 0.2260]]),\n",
      "               'mean': tensor([[0.5125, 0.9980, 0.2070]]),\n",
      "               'std': tensor([[0.0229, 0.0044, 0.0111]])}}\n"
     ]
    }
   ],
   "source": [
    "# Did we estimate the parameters correctly?\n",
    "posterior_predictive = Predictive(BN_model, guide=guide, num_samples=1000, return_sites=(\"A_weights\", \"B_weights\"))\n",
    "posterior_samples = posterior_predictive()\n",
    "print(\"SUMMARY: SAMPLES FROM POSTERIOR DISTRIBUTION\\n\")\n",
    "pprint(summarize_samples(posterior_samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
