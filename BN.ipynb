{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc035a02-9e8e-4ce0-bd83-40b434c16c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, Predictive, config_enumerate\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal, AutoDelta\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12ac954-b63a-4d85-bbc8-ca06f4d2168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @config_enumerate is \"required\" (not strictly) because we have a discrete variable, A\n",
    "# See https://pyro.ai/examples/enumeration.html\n",
    "@config_enumerate\n",
    "def BN_model(A_obs=None, B_obs=None, C_obs=None, N=None):\n",
    "    if A_obs is not None:\n",
    "        if B_obs is not None:\n",
    "            assert len(A_obs) == len(B_obs)\n",
    "        if C_obs is not None:\n",
    "            assert len(A_obs) == len(C_obs)\n",
    "        if N is not None:\n",
    "            assert N == len(A_obs)\n",
    "        else:\n",
    "            N = len(A_obs)\n",
    "\n",
    "        A_obs = A_obs.squeeze()\n",
    "\n",
    "    if B_obs is not None:\n",
    "        if N is not None:\n",
    "            assert N == len(B_obs)\n",
    "        else:\n",
    "            N = len(B_obs)\n",
    "\n",
    "        B_obs = B_obs.squeeze()\n",
    "\n",
    "    if C_obs is not None:\n",
    "        if N is not None:\n",
    "            assert N == len(C_obs)\n",
    "        else:\n",
    "            N = len(C_obs)\n",
    "\n",
    "        C_obs = C_obs.squeeze()\n",
    "\n",
    "    if N is None:\n",
    "        N = 1\n",
    "\n",
    "    # prior distribution over weights of the categorical distribution from which A is drawn\n",
    "    # pyro distinguishes between the \"batch_shape\" (=shape of samples drawn) and the \"event_shape\" (=shape of a single\n",
    "    # RV drawn from this distribution) of a tensor. We need to tell it that this 3-D thing describes a single RV (and\n",
    "    # similarly for the other priors below). See https://pyro.ai/examples/tensor_shapes.html for details.\n",
    "    weights = pyro.sample('weights', dist.Dirichlet(torch.ones(3)).to_event())\n",
    "\n",
    "    # prior distribution over parameters (> 0) of the beta distribution from which B is drawn\n",
    "    beta_concentrations = pyro.sample('beta_concentrations', dist.Gamma(concentration=torch.tensor([2., 2.]),\n",
    "                                                                        rate=torch.tensor([0.5, 0.5])).to_event())\n",
    "\n",
    "    # prior distribution over weigths k in p_C = B*k(A)\n",
    "    C_weights = pyro.sample('C_weights', dist.Beta(torch.tensor([1., 1., 1.]), torch.tensor([1., 1., 1.])).to_event())\n",
    "\n",
    "    if N > 0:\n",
    "        with pyro.plate('data', N):\n",
    "            A_dist = dist.Categorical(weights)\n",
    "            #ic(A_dist.batch_shape)\n",
    "            #ic(A_dist.event_shape)\n",
    "            #if A_obs is not None:\n",
    "            #    ic(A_obs.shape)\n",
    "            A = pyro.sample('A', A_dist, obs=A_obs, infer={\"enumerate\": \"parallel\"})\n",
    "            B_dist = dist.Beta(beta_concentrations[0], beta_concentrations[1])\n",
    "            #ic(B_dist.batch_shape)\n",
    "            #ic(B_dist.event_shape)\n",
    "            #if B_obs is not None:\n",
    "            #    ic(B_obs.shape)\n",
    "            B = pyro.sample('B', B_dist, obs=B_obs)\n",
    "            C = pyro.sample('C', dist.Binomial(probs=B * C_weights[A]), obs=C_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c826e6-f28a-4cdf-9b8f-64e783ac1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model (needs graphviz - don't have it, cannot test)\n",
    "#pyro.render_model(lambda: BN_model(N=100), render_distributions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b1d648-7816-46f0-a046-0a91f821325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def summarize_samples(samples):\n",
    "    # Adapted from https://pyro.ai/examples/bayesian_regression.html#Model-Evaluation.\n",
    "    param_stats = {}\n",
    "    for k, v in samples.items():\n",
    "        if torch.is_floating_point(v):\n",
    "            param_stats[k] = {\n",
    "                \"mean\": torch.mean(v, 0),\n",
    "                \"std\": torch.std(v, 0),\n",
    "                \"5%\": v.kthvalue(int(len(v) * 0.05), dim=0)[0],\n",
    "                \"95%\": v.kthvalue(int(len(v) * 0.95), dim=0)[0],\n",
    "            }\n",
    "        else:\n",
    "            print(f'Dropping variable {k} from summary statistics since it is not a float.')\n",
    "    return param_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44063684-4518-41b6-967b-b7d49ac03e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: SAMPLES FROM PRIOR DISTRIBUTION\n",
      "\n",
      "Dropping variable A from summary statistics since it is not a float.\n",
      "{'B': {'5%': tensor([0.0547]),\n",
      "       '95%': tensor([0.9386]),\n",
      "       'mean': tensor([0.4934]),\n",
      "       'std': tensor([0.2751])},\n",
      " 'C': {'5%': tensor([0.]),\n",
      "       '95%': tensor([1.]),\n",
      "       'mean': tensor([0.2200]),\n",
      "       'std': tensor([0.4145])},\n",
      " 'C_weights': {'5%': tensor([[0.0509, 0.0539, 0.0510]]),\n",
      "               '95%': tensor([[0.9461, 0.9481, 0.9499]]),\n",
      "               'mean': tensor([[0.4949, 0.5013, 0.5111]]),\n",
      "               'std': tensor([[0.2937, 0.2879, 0.2885]])},\n",
      " 'beta_concentrations': {'5%': tensor([[0.6700, 0.7640]]),\n",
      "                         '95%': tensor([[8.9570, 9.3770]]),\n",
      "                         'mean': tensor([[3.8575, 3.8982]]),\n",
      "                         'std': tensor([[2.7063, 2.7227]])},\n",
      " 'weights': {'5%': tensor([[0.0238, 0.0261, 0.0258]]),\n",
      "             '95%': tensor([[0.7493, 0.7722, 0.7515]]),\n",
      "             'mean': tensor([[0.3356, 0.3325, 0.3319]]),\n",
      "             'std': tensor([[0.2308, 0.2320, 0.2310]])}}\n"
     ]
    }
   ],
   "source": [
    "# Sample from the prior distribution, see here: https://forum.pyro.ai/t/samples-from-prior-distribution/1740/2\n",
    "prior_samples = Predictive(BN_model, posterior_samples={}, num_samples=1000)()\n",
    "print(\"SUMMARY: SAMPLES FROM PRIOR DISTRIBUTION\\n\")\n",
    "pprint(summarize_samples(prior_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbdf2951-3826-4f22-abe6-c6aecec29620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: SAMPLES FROM CONDITIONED DISTRIBUTION\n",
      "\n",
      "Dropping variable A from summary statistics since it is not a float.\n",
      "{'B': {'5%': tensor([0.0010]),\n",
      "       '95%': tensor([0.6618]),\n",
      "       'mean': tensor([0.2024]),\n",
      "       'std': tensor([0.2170])},\n",
      " 'C': {'5%': tensor([0.]),\n",
      "       '95%': tensor([1.]),\n",
      "       'mean': tensor([0.0792]),\n",
      "       'std': tensor([0.2701])},\n",
      " 'C_weights': {'5%': tensor([[0.5000, 1.0000, 0.2000]]),\n",
      "               '95%': tensor([[0.5000, 1.0000, 0.2000]]),\n",
      "               'mean': tensor([[0.5000, 1.0000, 0.2000]]),\n",
      "               'std': tensor([[0., 0., 0.]])},\n",
      " 'beta_concentrations': {'5%': tensor([[0.5000, 2.0000]]),\n",
      "                         '95%': tensor([[0.5000, 2.0000]]),\n",
      "                         'mean': tensor([[0.5000, 2.0000]]),\n",
      "                         'std': tensor([[0., 0.]])},\n",
      " 'weights': {'5%': tensor([[0.2000, 0.2000, 0.6000]]),\n",
      "             '95%': tensor([[0.2000, 0.2000, 0.6000]]),\n",
      "             'mean': tensor([[0.2000, 0.2000, 0.6000]]),\n",
      "             'std': tensor([[0., 0., 0.]])}}\n"
     ]
    }
   ],
   "source": [
    "# Specify some parameters and sample from the parametrized model\n",
    "# we'll see below whether we can then estimate those params\n",
    "weights = torch.tensor([0.2, 0.2, 0.6])\n",
    "beta_concentrations = torch.tensor([0.5, 2.0])\n",
    "C_weights = torch.tensor([0.5, 1.0, 0.2])\n",
    "BN_model_conditioned = pyro.poutine.condition(BN_model, data={'weights': weights,\n",
    "                                                              'beta_concentrations': beta_concentrations,\n",
    "                                                              'C_weights': C_weights})\n",
    "parametrized_samples = Predictive(BN_model_conditioned, posterior_samples={}, num_samples=5000)()\n",
    "print(\"SUMMARY: SAMPLES FROM CONDITIONED DISTRIBUTION\\n\")\n",
    "pprint(summarize_samples(parametrized_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0871d602-1b48-4b3c-a0af-567e72f134c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try to estimate those parameters using SVI\n",
    "pyro.clear_param_store()\n",
    "guide = AutoNormal(pyro.poutine.block(BN_model, hide=[\"A\", \"B\", \"C\"]))\n",
    "\n",
    "svi = SVI(model=BN_model,\n",
    "          guide=guide,\n",
    "          optim=ClippedAdam({\"lr\": 0.01, 'clip_norm': 1.0}),\n",
    "          loss=TraceEnum_ELBO(max_plate_nesting=1))  # if we didn't have a discrete variable, we'd use Trace_ELBO\n",
    "\n",
    "for i in range(5000):\n",
    "    loss = svi.step(parametrized_samples['A'], parametrized_samples['B'], parametrized_samples['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85157ee9-2061-47ed-9c4f-4ff2536d1e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: SAMPLES FROM POSTERIOR DISTRIBUTION\n",
      "\n",
      "{'C_weights': {'5%': tensor([[0.4659, 0.8215, 0.1502]]),\n",
      "               '95%': tensor([[0.6467, 0.9938, 0.2309]]),\n",
      "               'mean': tensor([[0.5590, 0.9421, 0.1885]]),\n",
      "               'std': tensor([[0.0570, 0.0659, 0.0243]])},\n",
      " 'beta_concentrations': {'5%': tensor([[0.4759, 1.8436]]),\n",
      "                         '95%': tensor([[0.5078, 2.0155]]),\n",
      "                         'mean': tensor([[0.4919, 1.9300]]),\n",
      "                         'std': tensor([[0.0098, 0.0518]])},\n",
      " 'weights': {'5%': tensor([[0.1916, 0.1859, 0.5772]]),\n",
      "             '95%': tensor([[0.2224, 0.2128, 0.6109]]),\n",
      "             'mean': tensor([[0.2070, 0.1990, 0.5939]]),\n",
      "             'std': tensor([[0.0092, 0.0080, 0.0105]])}}\n"
     ]
    }
   ],
   "source": [
    "# Did we estimate the parameters correctly?\n",
    "posterior_predictive = Predictive(BN_model, guide=guide, num_samples=1000, return_sites=(\"weights\", \"beta_concentrations\", \"C_weights\"))\n",
    "posterior_samples = posterior_predictive()\n",
    "print(\"SUMMARY: SAMPLES FROM POSTERIOR DISTRIBUTION\\n\")\n",
    "pprint(summarize_samples(posterior_samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
